# ğŸš€ Parallel gRPC Pipeline System

A fully distributed, horizontally-scaled microservice pipeline with **16 service instances**, **4 load balancers**, and full **parallel request processing**.

This project demonstrates how to build a real-world, production-style distributed system using **gRPC**, **Docker**, and **parallel pipelines**.

---

# ğŸŒŸ What This System Demonstrates

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚        DISTRIBUTED SYSTEM      â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
â€¢ Horizontal Scaling (4Ã— instances per service)
â€¢ Load Balancing (round-robin + failover)
â€¢ Parallel Processing (multi-pipeline execution)
â€¢ Service Discovery via internal LB routing
â€¢ Fault Tolerance (automatic rerouting on failure)
```

---

# ğŸ—ï¸ System Architecture

This system consists of **4 microservice stages**, each with:

* **1 Load Balancer**
* **4 Service Instances**

Total: **20 running containers** (16 services + 4 load balancers)

### ğŸ”„ High-Level Pipeline

```
Client
   â†“
Service1-LB (8061) â†’ Service1 instances (Ã—4)
   â†“
Service2-LB (8062) â†’ Service2 instances (Ã—4)
   â†“
Service3-LB (8063) â†’ Service3 instances (Ã—4)
   â†“
Service4-LB (8064) â†’ Service4 instances (Ã—4)
   â†“
Final Response
```

### ğŸ“˜ Detailed Architecture

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                             PARALLEL PIPELINE                                â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

Client
   â”‚
   â–¼
â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€  Stage 1: Service Group 1  â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
Load Balancer (Service1-LB:8061)
    â”œâ”€â”€ Service1a : 8051
    â”œâ”€â”€ Service1b : 8055
    â”œâ”€â”€ Service1c : 8057
    â””â”€â”€ Service1d : 8059
   â–¼
â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€  Stage 2: Service Group 2  â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
Load Balancer (Service2-LB:8062)
    â”œâ”€â”€ Service2a : 8052
    â”œâ”€â”€ Service2b : 8056
    â”œâ”€â”€ Service2c : 8058
    â””â”€â”€ Service2d : 8060
   â–¼
â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€  Stage 3: Service Group 3  â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
Load Balancer (Service3-LB:8063)
    â”œâ”€â”€ Service3a : 8053
    â”œâ”€â”€ Service3b : 8065
    â”œâ”€â”€ Service3c : 8067
    â””â”€â”€ Service3d : 8069
   â–¼
â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€  Stage 4: Service Group 4  â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
Load Balancer (Service4-LB:8064)
    â”œâ”€â”€ Service4a : 8054
    â”œâ”€â”€ Service4b : 8066
    â”œâ”€â”€ Service4c : 8068
    â””â”€â”€ Service4d : 8070
   â–¼
Response Back to Client
```

---

# ğŸ”„ How Data Flows Through the Pipeline

### **Single Request Path**

```
Client 
   â†’ Service1-LB (8061)
   â†’ Service1 instance
   â†’ Service2-LB (8062)
   â†’ Service2 instance
   â†’ Service3-LB (8063)
   â†’ Service3 instance
   â†’ Service4-LB (8064)
   â†’ Service4 instance 
   â†’ Response returned to client
```

### **Parallel Behavior**

Multiple requests (or text chunks) can move through the pipeline **independently and simultaneously**.

---

# ğŸ› ï¸ Commands Overview

## â–¶ï¸ Build & Start

```bash
make build        # Build all services + load balancers
make up           # Start entire distributed system
make restart      # Restart everything
```

## ğŸ§ª Testing Tools

```bash
make test         # Parallel file-splitting client
make benchmark    # Performance benchmarking (20 iterations)
make large-test   # Test large files (up to 100MB)
```

## ğŸ“¡ Monitoring

```bash
make logs               # View logs for all services
make logs-service1      # Logs for only Service1 instances
make logs-service2      # Logs for only Service2 instances
make logs-service3      # Logs for only Service3 instances
make logs-service4      # Logs for only Service4 instances
make logs-loadbalancers # View all load balancers
make status             # Show container status
```

## ğŸ§¹ Management

```bash
make down          # Stop all containers
make clean         # Stop & remove containers
make super-clean   # Remove everything (hard reset)
```

---

# âš™ï¸ How Parallel Processing Works

Running `make test` performs the following:

1. Reads a file from `/app/datasets/`
2. Splits it into **4 chunks**
3. Sends all chunks to **Service1-LB:8061**
4. LB distributes chunks to different Service1 instances
5. Each chunk independently traverses the entire pipeline
6. Client merges results into a single final output

This models how large systems process data across multiple parallel pipelines.

---

# ğŸŒ Load Balancer Logic

Each LB uses:

âœ” **Round-robin** request distribution
âœ” **Failover** retries when an instance is down
âœ” **Automatic fallback** until all instances fail
âœ” **Zero configuration** on client side

Clients only see a single endpoint per stage.

---

# ğŸ“Š Performance Testing Modes

### **Benchmark Mode (`make benchmark`)**

* Full text processed *per request*
* 20 iterations in batches of 4
* Measures:

  * Latency per request
  * Throughput
  * Parallel efficiency
  * Max & min timings

### **Parallel Client (`make test`)**

* Splits one file into 4 chunks
* Processes chunks simultaneously
* Measures end-to-end parallel speedup

### **Large File Client (`make large-test`)**

* Optimized for files up to **100MB**
* Tests 2-way and 4-way parallelism
* Designed for stress testing

---

# âš¡ Key Features

### ğŸŒ Horizontal Scaling

* 4 instances per service type
* Spread across load balancers
* Prevents bottlenecks and overload

### ğŸ›¡ï¸ Fault Tolerance

* LB retries on failure
* Pipeline continues even if multiple instances crash
* Graceful degradation under heavy load

### ğŸš€ Performance Optimizations

* 100MB message size limits
* 300-second timeouts
* Fully parallel request handling

---

# ğŸ”§ Troubleshooting

### Services Not Ready?

```bash
make up
sleep 15
make test
```

### Check container health:

```bash
make status
```

### View service logs:

```bash
docker-compose -f docker-compose-parallel.yml logs service1a
```

### Port Issues?

Ensure **8051â€“8070** and **8061â€“8064** are free.

### File Issues?

* Place files in `datasets/`
* Max tested size: **100MB**
* Automatically mounted into containers

